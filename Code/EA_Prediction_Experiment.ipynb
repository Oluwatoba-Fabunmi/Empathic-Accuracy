{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42873c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial import distance\n",
    "from torch.utils.data import  DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sentence_transformers import SentenceTransformer, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(df, batch_size):\n",
    "    train_sample = []\n",
    "    for _, x in df.iterrows():\n",
    "        train_sample.append(InputExample(texts=[x['user_thoughts_and _feelings'], x['designer_guess']], label=x['Avg_EA']))\n",
    "\n",
    "    return DataLoader(train_sample, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "def predict_scores(Designer, User):\n",
    "    return [1 - distance.cosine(Designer[i], User[i])\n",
    "                  for i in range(User.shape[0])]\n",
    "\n",
    "def evaluate(actual, predicted):\n",
    "    rmse = np.sqrt(np.mean((actual - predicted)**2))\n",
    "    pearson = pearsonr(actual, predicted)[0]\n",
    "    spearman = spearmanr(actual, predicted)[0]\n",
    "    print(\"Pearson:\", pearson)\n",
    "    print(\"spearman:\", spearman)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    return pearson,spearman, rmse\n",
    "\n",
    "def model_evaluate(model,sent_1,sent_2, actual):\n",
    "    s1 = model.encode(sent_1)\n",
    "    s2 = model.encode(sent_2)\n",
    "    scores = predict_scores(s1, s2)\n",
    "    pearson,spearman, rmse = evaluate(actual, scores)\n",
    "    return pearson,spearman, rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool = [ 'mean', 'cls','max','lasttoken','weightedmean']\n",
    "model_ = [ \"sentence-transformers/xlm-r-distilroberta-base-paraphrase-v1\",\n",
    "          \"princeton-nlp/sup-simcse-roberta-base\",\n",
    "          \"princeton-nlp/sup-simcse-bert-base-uncased\",\n",
    "          \"Contrastive-Tension/RoBerta-Large-CT-STSb\",\n",
    "          \"Contrastive-Tension/BERT-Base-CT-STSb\",\n",
    "          \"voidism/diffcse-roberta-base-sts\",\n",
    "          \"voidism/diffcse-bert-base-uncased-sts\",\n",
    "          \"kwang2049/TSDAE-askubuntu2nli_stsb\",\n",
    "           \"thenlper/gte-base\"\n",
    "          ]\n",
    "for i in model_:\n",
    "    for j in pool:\n",
    "        EA = (r\"ondemand/data/full data-EA-preprocessed.xlsx\")\n",
    "        data = pd.read_excel(EA)\n",
    "\n",
    "        data['Avg_EA'] = data[\"Average EA\"]/2\n",
    "        User= data[\"Users' thoughts or feeling\"]\n",
    "        Des= data[\"Inferences\"]\n",
    "        User = User.str.lower().str.replace(':','').str.replace('i was', '').str.replace('s/he was', '').str.replace('she was', '').str.replace('he was', '').str.replace('they were', '')\n",
    "        Des = Des.str.lower().str.replace(':','').str.replace('i was', '').str.replace('s/he was', '').str.replace('she was', '').str.replace('he was', '').str.replace('they were', '')\n",
    "\n",
    "        data['user_thoughts_and _feelings'] = User\n",
    "        data['designer_guess'] = Des\n",
    "\n",
    "        k = 10\n",
    "        print(k)\n",
    "        cross_val = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        epochs = 5\n",
    "        batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "        results = []\n",
    "        for k, (train, val) in enumerate(cross_val.split(data)):\n",
    "        \n",
    "            word_embedding_model = models.Transformer(i)\n",
    "            pooling_model= models.Pooling(word_embedding_model.get_word_embedding_dimension(),j)\n",
    "            model_new_ = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "            model = model_new_\n",
    "            model.to('cuda')\n",
    "            train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "            #AnglELoss\n",
    "            #CosineSimilarityLoss\n",
    "            train_df = data.iloc[train]\n",
    "            val_df = data.iloc[val]\n",
    "            train_dataloader = make_dataloader(train_df, batch_size=batch_size)\n",
    "            baseline_pearson,baseline_spearman, baseline_rmse = model_evaluate(model, val_df['user_thoughts_and _feelings'].values, val_df['designer_guess'].values,\n",
    "                                                        val_df['Avg_EA'].values\n",
    "                                                        )\n",
    "            model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs)\n",
    "            train_pearson, train_spearman, train_rmse = model_evaluate(model, train_df['user_thoughts_and _feelings'].values, train_df['designer_guess'].values,\n",
    "                                                  train_df['Avg_EA'].values\n",
    "                                                  )\n",
    "            val_pearson,val_spearman, val_rmse = model_evaluate(model, val_df['user_thoughts_and _feelings'].values, val_df['designer_guess'].values,\n",
    "                                              val_df['Avg_EA'].values\n",
    "                                              )\n",
    "\n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'train_pearson': train_pearson, 'train_spearman': train_spearman,'train_rmse': train_rmse,\n",
    "                'val_pearson': val_pearson, 'val_spearman': val_spearman,'val_rmse': val_rmse,\n",
    "                'baseline_pearson':baseline_pearson, 'baseline_spearman':baseline_spearman, 'baseline_rmse':baseline_rmse\n",
    "            })\n",
    "\n",
    "        #pd.DataFrame(results).to_csv('/content/drive/MyDrive/SBERT preprocessed Supervised results (1 Epoch).csv')\n",
    "        pd.DataFrame(results).to_csv('SBERT preprocessed Supervised results'+ str(x) + \" extra \" + j +' pooling (5 Epoch).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a5fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
