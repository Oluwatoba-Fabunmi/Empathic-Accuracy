{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "#print(transformers.__version__)\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer, losses, models,InputExample\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial import distance\n",
    "from torch.utils.data import  DataLoader,random_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_Train = load_dataset('glue', 'stsb', split = 'train')\n",
    "datasets_Val = load_dataset('glue', 'stsb', split = 'validation')\n",
    "datasets_Train = datasets_Train.remove_columns(['idx'])\n",
    "datasets_Val = datasets_Val.remove_columns(['idx'])\n",
    "\n",
    "datasets_Train = datasets_Train.add_column(\"label_div\", [i/5 for i in datasets_Train['label']]) \n",
    "datasets_Val = datasets_Val.add_column(\"label_div\", [i/5 for i in datasets_Val['label']]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01098558",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_data=[]\n",
    "Val = pd.DataFrame()\n",
    "Val_data.append((\"sentence1\",  [i for i in datasets_Val['sentence1']])) \n",
    "Val_data.append((\"sentence2\",  [i for i in datasets_Val['sentence2']]))\n",
    "Val_data.append((\"label_div\", [i/5 for i in datasets_Val['label']]))\n",
    "Val = pd.DataFrame.from_dict(dict(Val_data))\n",
    "\n",
    "\n",
    "Train_data=[]\n",
    "Train = pd.DataFrame()\n",
    "Train_data.append((\"sentence1\",  [i for i in datasets_Train['sentence1']])) \n",
    "Train_data.append((\"sentence2\",  [i for i in datasets_Train['sentence2']]))\n",
    "Train_data.append((\"label_div\", [i/5 for i in datasets_Train['label']]))\n",
    "Train = pd.DataFrame.from_dict(dict(Train_data))\n",
    "#Val['label_div'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d103b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_to_loader= []\n",
    "#Val = []\n",
    "\n",
    "for row in tqdm(datasets_Train):\n",
    "    Train_to_loader.append(InputExample(texts=[row['sentence1'],row['sentence2']],label=row['label_div']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c48758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Conv_2_Dataloader(df, batch_size):\n",
    "     return DataLoader(df, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "def predict_scores(Designer, User):\n",
    "    return [1 - distance.cosine(Designer[i], User[i])\n",
    "                  for i in range(User.shape[0])]\n",
    "\n",
    "def evaluate(actual, predicted):\n",
    "    rmse = np.sqrt(np.mean((actual - predicted)**2))\n",
    "    pearson = pearsonr(actual, predicted)[0]\n",
    "    spearman = spearmanr(actual, predicted)[0]\n",
    "    print(\"Pearson:\", pearson)\n",
    "    print(\"spearman:\", spearman)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    return pearson,spearman, rmse\n",
    "\n",
    "def model_evaluate(model,sent_1,sent_2, actual):\n",
    "    s1 = model.encode(sent_1)\n",
    "    s2 = model.encode(sent_2)\n",
    "    scores = predict_scores(s1, s2)\n",
    "    pearson,spearman, rmse = evaluate(actual, scores)\n",
    "    return pearson,spearman, rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "epoch = ['mean', 'cls','max','lasttoken','weightedmean']\n",
    "model_ = [\"sentence-transformers/xlm-r-distilroberta-base-paraphrase-v1\",\n",
    "          #\"princeton-nlp/sup-simcse-roberta-base\",\n",
    "          #\"princeton-nlp/sup-simcse-bert-base-uncased\",\n",
    "          #\"Contrastive-Tension/BERT-Base-CT-STSb\",\n",
    "          #\"voidism/diffcse-roberta-base-sts\",\n",
    "          #\"voidism/diffcse-bert-base-uncased-sts\",\n",
    "          #\"kwang2049/TSDAE-askubuntu2nli_stsb\",\n",
    "          #\"thenlper/gte-base\"\n",
    "          ]\n",
    "for i in model_:\n",
    "    for j in epoch:\n",
    "        x +=1\n",
    "        epochs = 5\n",
    "        batch_size = 1\n",
    "        results = []\n",
    "\n",
    "        word_embedding_model = models.Transformer(i)\n",
    "        pooling_model= models.Pooling(word_embedding_model.get_word_embedding_dimension(), j)\n",
    "        model_new_ = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "        model = model_new_\n",
    "        model.to('cuda')\n",
    "        train_loss = losses.CosineSimilarityLoss(model=model)  #CosineSimilarityLoss  CoSENTLoss\n",
    "        \n",
    "        #train_df = data.iloc[train]\n",
    "        #val_df = data.iloc[val]\n",
    "        train_dataloader =  Conv_2_Dataloader(Train_to_loader, batch_size=batch_size)\n",
    "        baseline_pearson,baseline_spearman, baseline_rmse = model_evaluate(model, Val['sentence1'].values, Val['sentence2'].values,\n",
    "                                                    Val['label_div'].values\n",
    "                                                    )\n",
    "        model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs, output_path=('/sbert_STS_b ' +j + ' '+ str(x)))\n",
    "\n",
    "        train_pearson, train_spearman, train_rmse = model_evaluate(model, Train['sentence1'].values, Train['sentence2'].values,\n",
    "                                                    Train['label_div'].values\n",
    "                                                                  )\n",
    "        \n",
    "        val_pearson,val_spearman, val_rmse = model_evaluate(model, Val['sentence1'].values, Val['sentence2'].values,\n",
    "                                                    Val['label_div'].values\n",
    "\n",
    "                                                           )\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            'train_pearson': train_pearson, 'train_spearman': train_spearman,'train_rmse': train_rmse,\n",
    "            'val_pearson': val_pearson, 'val_spearman': val_spearman,'val_rmse': val_rmse,\n",
    "            'baseline_pearson':baseline_pearson, 'baseline_spearman':baseline_spearman, 'baseline_rmse':baseline_rmse\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52266bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
