{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1face3-4e0c-49c1-8f83-e75c74d2d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer, losses,  InputExample, models\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial import distance\n",
    "from torch.utils.data import  DataLoader,random_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(df, batch_size):\n",
    "    train_sample = []\n",
    "    for _, x in df.iterrows():\n",
    "        train_sample.append(InputExample(texts=[x['user_thoughts_and _feelings'], x['designer_guess']], label=x['Avg_EA']))\n",
    "\n",
    "    return DataLoader(train_sample, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "def predict_scores(Designer, User):\n",
    "    return [1 - distance.cosine(Designer[i], User[i])\n",
    "                  for i in range(User.shape[0])]\n",
    "\n",
    "def evaluate(actual, predicted):\n",
    "    rmse = np.sqrt(np.mean((actual - predicted)**2))\n",
    "    pearson = pearsonr(actual, predicted)[0]\n",
    "    spearman = spearmanr(actual, predicted)[0]\n",
    "    print(\"Pearson:\", pearson)\n",
    "    print(\"spearman:\", spearman)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    return pearson,spearman, rmse\n",
    "\n",
    "def model_evaluate(model,sent_1,sent_2, actual):\n",
    "    s1 = model.encode(sent_1)\n",
    "    s2 = model.encode(sent_2)\n",
    "    scores = predict_scores(s1, s2)\n",
    "    pearson,spearman, rmse = evaluate(actual, scores)\n",
    "    return pearson,spearman, rmse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449332d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "# Pooling method\n",
    "pool = ['weightedmean'] #, 'cls','max','lasttoken','mean']\n",
    "#The models saved after fine-tuning on STS-B train dataset is used \n",
    "model_ = [\"/sbert_test_b weightedmean 105\",\n",
    "          \"/sbert_test_b weightedmean 110\",\n",
    "          \"/sbert_test_b weightedmean 115\",\n",
    "          \"/sbert_test_b weightedmean 120\",\n",
    "          \"/sbert_test_b weightedmean 125\",\n",
    "          \"/sbert_test_b weightedmean 130\",\n",
    "          \"/sbert_test_b weightedmean 135\",\n",
    "          \"/sbert_test_b weightedmean 140\"\n",
    "          ]\n",
    "for i in model_:\n",
    "    for j in pool:\n",
    "        x +=1\n",
    "\n",
    "        EA = (r\"EA Data/EMPATHIC ACCURACY DATASET.xlsx\" )\n",
    "        data = pd.read_excel(EA)\n",
    "\n",
    "        data['Avg_EA'] = data[\"Empathic Accuracy (EA)\"]/2\n",
    "        User= data[\"User's thoughts or feelings\"]\n",
    "        Des= data[\"Designer's guess\"]\n",
    "        User = User.str.lower().str.replace(':','').str.replace('i was', '').str.replace('she / he was', '').str.replace('s/he was', '').str.replace('she was', '').str.replace('he was', '').str.replace('they were', '')\n",
    "        Des = Des.str.lower().str.replace(':','').str.replace('i was', '').str.replace('she / he was', '').str.replace('s/he was', '').str.replace('she was', '').str.replace('he was', '').str.replace('they were', '')\n",
    "\n",
    "        data['user_thoughts_and _feelings'] = User\n",
    "        data['designer_guess'] = Des\n",
    "\n",
    "        k = 10\n",
    "        print(k)\n",
    "        cross_val = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "        #model_id = \"sentence-transformers/xlm-r-distilroberta-base-paraphrase-v1\" #princeton-nlp/sup-simcse-roberta-large\"\n",
    "        epochs = 5\n",
    "        batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "        results = []\n",
    "        User_Sent = []\n",
    "        Des_Sent = []\n",
    "        EA_score = []\n",
    "        Pred_score = []\n",
    "        Comp_eval =[]\n",
    "        \n",
    "        for k, (train, val) in enumerate(cross_val.split(data)):\n",
    "            word_embedding_model = models.Transformer(i)\n",
    "            pooling_model= models.Pooling(word_embedding_model.get_word_embedding_dimension(), j)\n",
    "\n",
    "            model_new_ = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "            model = model_new_\n",
    "            model.to('cuda')\n",
    "            train_loss = losses.CosineSimilarityLoss(model=model) \n",
    "            train_df = data.iloc[train]\n",
    "            val_df = data.iloc[val]\n",
    "            train_dataloader = make_dataloader(train_df, batch_size=batch_size)\n",
    "            baseline_pearson,baseline_spearman, baseline_rmse = model_evaluate(model, val_df['user_thoughts_and _feelings'].values, val_df['designer_guess'].values,\n",
    "                                                        val_df['Avg_EA'].values\n",
    "                                                        )\n",
    "            model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs)\n",
    "            train_pearson, train_spearman, train_rmse = model_evaluate(model, train_df['user_thoughts_and _feelings'].values, train_df['designer_guess'].values,\n",
    "                                                  train_df['Avg_EA'].values\n",
    "                                                  )\n",
    "            val_pearson,val_spearman, val_rmse = model_evaluate(model, val_df['user_thoughts_and _feelings'].values, val_df['designer_guess'].values,\n",
    "                                              val_df['Avg_EA'].values\n",
    "                                                                \n",
    "                                                               )\n",
    "\n",
    "\n",
    "                                   \n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'train_pearson': train_pearson, 'train_spearman': train_spearman,'train_rmse': train_rmse,\n",
    "                'val_pearson': val_pearson, 'val_spearman': val_spearman,'val_rmse': val_rmse,\n",
    "                'baseline_pearson':baseline_pearson, 'baseline_spearman':baseline_spearman, 'baseline_rmse':baseline_rmse\n",
    "            })\n",
    "        \n",
    "\n",
    "        pd.DataFrame(results).to_csv('Out-In-Domain for the different models '  +j + ' '+ str(x) +' .csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
